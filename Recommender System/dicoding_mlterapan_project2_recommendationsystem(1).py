# -*- coding: utf-8 -*-
"""dicoding-mlterapan-project2-recommendationsystem(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MFO5G2_NoUfGmuJKUIXLc18VUbWd-lQ3

# Projek Akhir Machine Learning - Sukron Chafidhi

![animes](https://res.cloudinary.com/da0hsihog/image/upload/v1690711687/Portofolio/animes_wtf6kl.jpg)

Anime adalah istilah Jepang untuk segala jenis animasi, tak peduli dari negara mana asalnya. Industri anime tumbuh pesat dari tahun 2013 hingga 2018, dengan pasar rata-rata sekitar 2 triliun yen. Pada tahun 2018, pasar luar negeri mencapai lebih dari 1 triliun yen, atau sekitar 46,3% dari total pasar animasi Jepang. Pertumbuhan ini menghasilkan banyak karya anime baru untuk dinikmati pengguna. Namun, keberagaman anime bisa membuat pengguna kesulitan mencari anime sesuai preferensi mereka. Sistem rekomendasi adalah solusi untuk menyandingkan pengguna dengan anime yang cocok secara otomatis, tanpa mencari manual.

List Content:
* [Project Overview](#scrollTo=RiltQKQDy-g5)
* [Business Understanding](#scrollTo=jhiEw3kPy-hB)
* [Data Understanding](#scrollTo=wcgn9-Uoy-hE)
* [Exploratory Data Analysis - Univariate](#scrollTo=ia6Sthzty-hQ)
* [Data Preparation](#scrollTo=j30Q4LIfy-hY)
* [Modelling and Results](#scrollTo=zJ0eHx-Jy-hk)
* [Evaluation](#scrollTo=p2GVmBudy-hr)

## Business Understanding
Problem Statements

•	Bagaimana cara merekomendasikan anime berdasarkan riwayat user?

•	Bagaimana cara merekomendasikan anime berdasarkan penilaian user lain?

Goals

•	Membuat Sistem Rekomendasi anime berdasarkan riwayat user

•	Membuat Sistem Rekomendasi anime berdasarkan penilaian user lain

## Data Understanding

Variabel-variabel yang terdapat pada dataset adalah sebagai berikut:

### animelist.csv
Dataset ini berisi daftar semua anime yang terdaftar oleh pengguna berserta skor, status menonton, dan jumlah episode yang telah ditonton oleh pengguna. Terdapat 20 juta baris data, 16.745 anime berbeda, dan 74.129 pengguna berbeda dalam dataset ini. File tersebut memiliki kolom-kolom berikut:

1. user_id: ID pengguna yang dihasilkan secara acak dan tidak dapat diidentifikasi.
2. anime_id: ID Anime-planet dari anime tersebut. (contoh: 1).
3. score: Nilai antara 1 hingga 5 yang diberikan oleh pengguna dalam skala 0.5. Nilai 0 jika pengguna tidak memberikan penilaian. (contoh: 3.5).
4. watching_status: ID status dari anime tersebut dalam daftar anime pengguna. (contoh: 2).
5. watched_episodes: Jumlah episode yang telah ditonton oleh pengguna. (contoh: 24).

### watching_status.csv
Berikut adalah deskripsi dari setiap kemungkinan status dalam kolom "watching_status" dalam file animelist.csv:
•	Watched: Sudah Ditonton
•	Watching: Sedang Ditonton
•	Dropped: Dihentikan (Tidak Dilanjutkan)
•	Want to Watch: Ingin Ditonton
•	Stalled: Mandek (Ditunda)
•	Won't Watch: Tidak Akan Ditonton


### rating_complete.csv
Ini adalah subset dari animelist.csv. Dataset ini hanya mempertimbangkan anime-anime yang telah ditonton secara lengkap oleh pengguna (watching_status==1) dan diberi penilaian (score!=0). Dataset ini berisi 8 juta penilaian yang diberikan untuk 15.681 anime oleh 68.199 pengguna. File ini memiliki kolom-kolom berikut:
Berikut adalah terjemahan dari kolom-kolom dataset:

- user_id: ID pengguna yang dihasilkan secara acak dan tidak dapat diidentifikasi.
- anime_id: ID Anime-planet dari anime tersebut. (contoh: 1).
- rating: Nilai penilaian yang diberikan oleh pengguna untuk anime ini.


### anime_recommendations.csv
File ini berisi daftar semua anime yang direkomendasikan berdasarkan satu anime tertentu. Informasi ini diambil dari tab "recommendation" (misalnya: https://www.anime-planet.com/anime/the-saints-magic-power-is-omnipotent/recommendations ). File ini memiliki kolom-kolom berikut:

- Anime: ID Anime Planet dari anime tertentu. (contoh: 1).
- Recommendation: ID Anime Planet dari anime yang direkomendasikan. (contoh: 1).
- Agree Votes: jumlah pengguna yang setuju dengan rekomendasi tersebut.


### anime.csv
File ini berisi informasi umum dari setiap anime (16.621 anime berbeda) seperti Tag, tipe, studio, sinopsis, dan lain-lain. File ini memiliki kolom-kolom berikut:

- Anime-PlanetID: ID Anime Planet dari anime tersebut. (contoh: 1).
- Nama: nama lengkap dari anime tersebut. (contoh: FLCL)
- Nama Alternatif: cara lain untuk menyebut anime tersebut. (contoh: Furi Kuri)
- Skor Rating: skor rata-rata dari anime tersebut yang diberikan oleh seluruh pengguna di database Anime Planet. (contoh: 8.78)
- Jumlah Suara: jumlah pengguna yang memberikan skor untuk anime tersebut. (contoh: 1241)
- Tag: daftar tag yang dipisahkan dengan koma untuk anime tersebut. (contoh: Comedy, Mecha, Sci Fi, Outer Space, Original Work)
- Peringatan Konten: daftar tag peringatan konten yang dipisahkan dengan koma. (contoh: Explicit Violence, Mature Themes, Nudity)
- Tipe: TV, film, OVA, dll. (contoh: TV).
- Episode: jumlah episode. (contoh: 26)
- Selesai: Benar (True) jika anime tersebut sudah selesai ketika data diambil, Salah (False) jika anime tersebut masih berlanjut saat itu.
- Durasi: durasi anime dalam menit (contoh: 60)
- Tahun Mulai: tahun ketika anime mulai ditayangkan. (contoh: 2016)
- Tahun Selesai: tahun ketika anime selesai ditayangkan. (contoh: 2017)
- Musim: musim dan tahun rilis (contoh: Fall 2000)
- Studio: daftar studio yang dipisahkan dengan koma (contoh: Sunrise)
- Sinopsis: sinopsis dari anime tersebut.
- URL: tautan ke halaman utama anime di Anime Planet (contoh: https://www.anime-planet.com/anime/vandread)

list semua file
"""

# Commented out IPython magic to ensure Python compatibility.
# %ls /kaggle/input/animeplanet-recommendation-database-2020

"""install seaborn"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install seaborn

"""import library"""

import pandas as pd
import numpy as np
import seaborn as sns
import re
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer

"""load dataset"""

animelist = pd.read_csv('/kaggle/input/animeplanet-recommendation-database-2020/animelist.csv')
watching_status = pd.read_csv('/kaggle/input/animeplanet-recommendation-database-2020/watching_status.csv')
rating_complete = pd.read_csv('/kaggle/input/animeplanet-recommendation-database-2020/rating_complete.csv')
anime_recommendations = pd.read_csv('/kaggle/input/animeplanet-recommendation-database-2020/anime_recommendations.csv')
anime = pd.read_csv('/kaggle/input/animeplanet-recommendation-database-2020/anime.csv')

"""Format nama kolom dengan mendeklarasikan fungsi"""

def columns_formater(data):
    for column in data:
        try:
          data = data.rename(
            columns = {column : column.lower()
            .replace(" ", "_")
            .replace("-", "_")
            .replace("[", "")
            .replace("]", "")})
        except:
          pass

    return data

"""Menerapkan format"""

animelist = columns_formater(animelist)
watching_status = columns_formater(watching_status)
rating_complete = columns_formater(rating_complete)
anime_recommendations = columns_formater(anime_recommendations)
anime = columns_formater(anime)

"""Print informasi jumlah per variabel"""

print('Jumlah data user: ', len(animelist.user_id.unique()))
print('Jumlah data anime yang didaftarkan user: ', len(animelist.anime_id.unique()))
print('Jumlah data anime: ', len(anime.anime_planetid.unique()))
print('Jumlah data anime ber-rating dan selesai ditonton: ', len(rating_complete.anime_id.unique()))
print('Jumlah kategori status ditonton: ', len(watching_status.status.unique()))
print('Rekomendasi anime berdasarkan anime yang dilihat: ', len(anime_recommendations.anime.unique()))

# Tampilkan grafik anime yang paling banyak dilihat
top_10_anime = anime['name'].value_counts().nlargest(10)
palette = sns.color_palette('rocket', len(top_10_anime))

# Buat grafik
plt.bar(top_10_anime.index, top_10_anime.values, color=palette)

# Set judul dan label
plt.title('Top 10 Anime by User Most Watch')
plt.xlabel('Anime Name')
plt.ylabel('User Watch Count')
plt.xticks(rotation=40, ha="right")

# Tampilkan plot
plt.show()

"""## Exploratory Data Analysis

### Univariate
Variabel-variabel pada Animeplanet Recommendation dataset adalah sebagai berikut:
* animelist: list anime yang terdaftar user
* watching_status: kategori untuk status anime ditonton
* rating_complete: list anime yang telah ditonton hingga selesai dan memiliki rating
* anime_recommendations: list anime yang direkomendasikan berdasarkan suatu anime yang dipilih (tidak digunakan)
* anime: informasi umum untuk setiap anime

### Variabel Anime List
"""

animelist.info()

print('Banyak user yang mendaftarkan anime: ', len(animelist.user_id.unique()))
print('Banyak anime didaftarkan: ', len(animelist.anime_id.unique()))

"""### Variabel Watching Status"""

watching_status.info()

print('Banyak data: ', len(watching_status.status.unique()))
print('Jenis Status: ', watching_status._description.unique())

"""### Variabel Rating Complete"""

rating_complete.describe().round(3)

print('Jumlah user_id: ', len(rating_complete.user_id.unique()))
print('Jumlah anime_id: ', len(rating_complete.anime_id.unique()))
print('Jumlah data rating: ', len(rating_complete))

"""### Variabel Anime"""

anime.info()

print('Jumlah anime: ', len(anime.anime_planetid.unique()))
print('Jumlah tags: ', len(anime.tags.unique()))

"""## Data Preparation

Seleksi fitur
"""

anime_data = anime[['anime_planetid', 'name', 'rating_score', 'tags']]

anime_data.info()

"""Seleksi fitur ke variabel baru"""

animelist_data = animelist.iloc[:,:3]

animelist_data.info()

"""Menggabungkan Fitur"""

anime_complete = pd.merge(anime_data, animelist_data, left_on='anime_planetid', right_on='anime_id').drop(columns='anime_planetid')


first_column = anime_complete.pop('anime_id')

anime_complete.insert(0, 'anime_id', first_column)

anime_complete.head()

anime_complete.info()

"""Cek missing value"""

anime_complete.isna().sum()

"""Copy nilai ke variabel baru"""

anime_features = anime_complete.copy()
anime_features.head()

"""Bersihkan teks"""

def text_cleaning(text):
    text = re.sub(r'&quot;', '', text)
    text = re.sub(r'.hack//', '', text)
    text = re.sub(r'&#039;', '', text)
    text = re.sub(r'A&#039;s', '', text)
    text = re.sub(r'I&#039;', 'I\'', text)
    text = re.sub(r'&amp;', 'and', text)

    return text

"""Terapkan pembersihan teks"""

anime_features['name'] = anime_features['name'].apply(text_cleaning)

anime_features

"""Cek missing value"""

anime_features.isnull().sum()

"""Membuat variabel preparation yang berisi dataframe anime_features kemudian mengurutkan berdasarkan anime_id"""

preparation = anime_features
preparation.sort_values('anime_id', ascending=True)

"""Membuang data duplikat pada variabel preparation"""

preparation = preparation.drop_duplicates('anime_id')
preparation

data = preparation
data.sample(5)

"""### Preparation - Content Based Filtering

Replace tanda koma dengan spasi
"""

tags_combined = data['tags'].str.replace(',', ' ')
tags_combined

"""### Preparation - Collaborative Filtering

Seleksi fitur
"""

data_cbf = data.drop(['rating_score', 'tags'], axis=1)
data_cbf

"""Membuat dataframe rating_df yang menyimpan data user jika telah me-rating setidaknya 10 anime"""

# user harus sudah me-rate minimal 10 anime
n_ratings = data_cbf['user_id'].value_counts()
rating_df = data_cbf[data_cbf['user_id'].isin(n_ratings[n_ratings >= 10].index)].copy()
len(rating_df)

"""Scaling BTW (0 , 1.0)"""

min_rating = min(rating_df['rating'])
max_rating = max(rating_df['rating'])
rating_df['rating'] = rating_df["rating"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values.astype(np.float64)

AvgRating = np.mean(rating_df['rating'])
print('Avg', AvgRating)

duplicates = rating_df.duplicated()

if duplicates.sum() > 0:
    print('> {} duplicates'.format(duplicates.sum()))
    rating_df = rating_df[~duplicates]

print('> {} duplicates'.format(rating_df.duplicated().sum()))

"""Encoding"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = rating_df['user_id'].unique().tolist()

# Melakukan encoding userID
user2user_encoded  = {x: i for i, x in enumerate(user_ids)}

# Melakukan proses encoding angka ke ke user_id
user_encoded2user = {i: x for i, x in enumerate(user_ids)}
rating_df["user"] = rating_df["user_id"].map(user2user_encoded)
n_users = len(user2user_encoded)


anime_ids = rating_df['anime_id'].unique().tolist()
anime2anime_encoded  = {x: i for i, x in enumerate(anime_ids)}

# Melakukan proses encoding angka ke anime_ids
anime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}

rating_df["anime"] = rating_df["anime_id"].map(anime2anime_encoded)
n_animes = len(anime2anime_encoded)

print("Num of users: {}, Num of animes: {}".format(n_users, n_animes))
print("Min rating: {}, Max rating: {}".format(min(rating_df['rating']), max(rating_df['rating'])))

"""Split train test data dengan rasio 80:20"""

rating_df = rating_df.sample(frac=1, random_state=39)

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = rating_df[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = rating_df['rating'].values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * rating_df.shape[0])
x_train, x_test, y_train, y_test = (
      x[:train_indices],
      x[train_indices:],
      y[:train_indices],
      y[train_indices:]
  )

print('> Train set ratings: {}'.format(len(y_train)))
print('> Test set ratings: {}'.format(len(y_test)))

"""Membuat array untuk train dan test"""

x_train_array = [x_train[:, 0], x_train[:, 1]]
x_test_array = [x_test[:, 0], x_test[:, 1]]
x_train_array

"""## Modeling and Result

### Content Based Filtering - Modelling
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# fit dan transformasi ke dalam bentuk matriks
tfidf_matrix = tf.fit_transform(tags_combined)

# Mapping array dari fitur index integer ke fitur nama
tfidf_matrix.shape

"""Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()"""

tfidf_matrix.todense()

"""Lihat matriks tf-idf"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.name
).sample(50, axis=1).sample(10, axis=0)

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama anime"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['name'], columns=data['name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap anime
cosine_sim_df

"""Deklarasi fungsi untuk mendapatkan rekomendasi"""

def anime_recommendations(nama_anime, similarity_data=cosine_sim_df, items=data[['name', 'tags']], k=5):
        # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
        # Dataframe diubah menjadi numpy
        # Range(start, stop, step)
        index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
            range(-1, -k, -1))

        # Mengambil data dengan similarity terbesar dari index yang ada
        closest = similarity_data.columns[index[-1:-(k+2):-1]]

        # Drop nama_anime agar nama anime yang dicari tidak muncul dalam daftar rekomendasi
        closest = closest.drop(nama_anime, errors='ignore')

        return pd.DataFrame(closest).merge(items).head(k)

"""### Content Based Filtering - Result

Mendapatkan nama anime random
"""

anime_title = np.random.choice(data.name)
anime_title
data[data.name.eq(anime_title)]

"""Mendapatkan nama anime rekomendasi"""

anime_recommendations(anime_title)

"""### Collaborative Based Filtering - Modelling

Membuat fungsi rekomender dengan Collaborative Based Filtering
"""

import tensorflow as tf
from tensorflow.keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten
from tensorflow.keras.models import Model

def RecommenderNet(num_users, num_anime, embedding_size):

        user = Input(name = 'user', shape = [1])
        embedding_size = embedding_size

        user_embedding = Embedding( # layer embedding user
            name = 'user_embedding',
            input_dim = num_users,
            output_dim = embedding_size,
        )(user)

        anime = Input(name = 'anime', shape = [1])
        anime_embedding = Embedding( # layer embeddings anime
            name = 'anime_embedding',
            input_dim = num_anime,
            output_dim = embedding_size)(anime)


        x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, anime_embedding])
        x = Flatten()(x)

        x = Dense(1, kernel_initializer='he_normal')(x)
        x = BatchNormalization()(x)
        x = Activation("sigmoid")(x)

        model = Model(inputs=[user, anime], outputs=x)


        return model

"""Inisialisasi model dan tampilkan summary"""

model = RecommenderNet(n_users, n_animes, 50) # inisialisasi model

# model compile
model.compile(
        loss = tf.keras.losses.BinaryCrossentropy(),
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
        metrics=[tf.keras.metrics.RootMeanSquaredError()]
        )

model.summary()

"""Buat callback ModelCheckPoint untuk menyimpan hasil pelatihan terbaik"""

from tensorflow.keras.callbacks import ModelCheckpoint

model_checkpoints = ModelCheckpoint(filepath='./weights.h5',
                                        save_weights_only=True,
                                        monitor='val_loss',
                                        mode='min',
                                        save_best_only=True)


my_callbacks = [
    model_checkpoints,
]

"""Memulai training"""

history = model.fit(
        x = x_train_array,
        y = y_train,
        batch_size = 8,
        epochs = 100,
        validation_data = (x_test_array, y_test),
        callbacks=my_callbacks,
    )

"""Me-load model terbaik yang telah disimpan dengan callback ModelCheckPoint"""

model.load_weights('./weights.h5')

"""Replace Unknown menjadi NaN"""

df_test = anime
df_test = df_test.replace("Unknown", np.nan)
df_test

"""Rubah nama kolom anime_planetid menjadi anime_id"""

df_test.rename(columns = {'anime_planetid':'anime_id'}, inplace = True)

"""Buat fungsi untuk mendapatkan rekomendasi, dimana hasil rekomendasi merupakan anime yang belum pernah ditonton"""

def get_recommendations(user_id, recom_n=5):
    print("===" * 10)
    print("Recommendation for id: {}".format(user_id))
    print("===" * 10)

    animes_watched_by_user = rating_df[rating_df.user_id==user_id]
    anime_not_watched_df = df_test[
        ~df_test["anime_id"].isin(animes_watched_by_user.anime_id.values)
    ]

    anime_not_watched = list(
        set(anime_not_watched_df['anime_id']).intersection(set(anime2anime_encoded.keys()))
    )

    anime_not_watched = [[anime2anime_encoded.get(x)] for x in anime_not_watched]

    user_encoder = user2user_encoded.get(user_id)

    user_anime_array = np.hstack(
        ([[user_encoder]] * len(anime_not_watched), anime_not_watched)
    )

    user_anime_array = [user_anime_array[:, 0], user_anime_array[:, 1]]
    ratings = model.predict(user_anime_array).flatten()

    top_ratings_indices = (-ratings).argsort()[:recom_n]

    recommended_anime_ids = [
        anime_encoded2anime.get(anime_not_watched[x][0]) for x in top_ratings_indices
    ]

    Results = []
    top_rated_ids = []

    for index, anime_id in enumerate(anime_not_watched):
        rating = ratings[index]
        id_ = anime_encoded2anime.get(anime_id[0])

        if id_ in recommended_anime_ids:
            top_rated_ids.append(id_)
            try:
                condition = (df_test.anime_id == id_)
                name = df_test[condition]['name'].values[0]
                sypnopsis = df_test[condition].synopsis.values[0]
                tags = df_test[condition].tags.values[0]
            except:
                continue

            Results.append({#"anime_id": id_,
                            "name": name,
                            "pred_rating": rating,
                            "tags": tags,
                            'sypnopsis': sypnopsis} )


    print('>>>>>>>> Top ',recom_n,' anime recommendations for you <<<<<<<<<<<<')


    Results = pd.DataFrame(Results).sort_values(by='pred_rating', ascending=False)
    return Results

"""### Collaborative Based Filtering - Result

Mendapatkan user id random
"""

ratings_per_user = rating_df.groupby('user_id').size()
random_user = ratings_per_user[ratings_per_user < 500].sample(1, random_state=None).index[0]
print('> user_id:', random_user)

"""Mendapatkan rekomendasi anime"""

get_recommendations(random_user)

"""## Evaluation

## Content Based Filtering
Data yang akan diberi rekomendasi

| anime_id 	|  name 	|             rating_score 	|  tags 	|         user_id 	| rating 	|     	|
|---------:	|------:	|-------------------------:	|------:	|----------------:	|-------:	|-----	|
|  2269159 	| 12689 	| THE CHARM PARK: Timeless 	| 2.529 	| Abstract, Aging 	| 1635   	| 0.0 	|


Hasil rekomendasi

|   	|              name             	|                        tags                       	|
|--:	|:-----------------------------:	|:-------------------------------------------------:	|
| 0 	| Furiko                        	| Drama, Romance, Aging, Black and White, Shorts    	|
| 1 	| Best Care Group               	| Slice of Life, Aging, No Dialogue, Promotional... 	|
| 2 	| The Sakuramoto Broom Workshop 	| Drama, Aging, No Dialogue, Shorts, Stop Motion... 	|
| 3 	| Walls                         	| Abstract                                          	|
| 4 	| Canigou: Tape                 	| Abstract                                          	|

rekomendasi dianggap benar jika memiliki salah satu tags dari tags data referensi (yang diberi rekomendasi) sehingga dapat dihitung nilai precision nya,

$$
Precision = \frac{rekomendasi yang relevan}{jumlah yang direkomendasikan}
$$

$$
Precision = \frac{5}{5}
$$

Sehingga didapatkan nilai presisinya 100%

### Collaborative Based Filtering

Tampilkan plot metrik RMSE
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

